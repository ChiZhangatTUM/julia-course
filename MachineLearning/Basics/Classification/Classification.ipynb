{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation to go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Including the Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation of MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[2K\u001b[?25h[1mFetching:\u001b[22m\u001b[39m [========================================>]  100.0 %.0 %\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m RecursiveArrayTools ─ v2.0.4\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m BSON ──────────────── v0.2.5\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      " \u001b[90m [fbb218c0]\u001b[39m\u001b[92m + BSON v0.2.5\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      " \u001b[90m [fbb218c0]\u001b[39m\u001b[92m + BSON v0.2.5\u001b[39m\n",
      " \u001b[90m [731186ca]\u001b[39m\u001b[93m ↑ RecursiveArrayTools v2.0.2 ⇒ v2.0.4\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"BSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling BSON [fbb218c0-5317-5bc6-957e-2ee96dd4b1f0]\n",
      "└ @ Base loading.jl:1242\n"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "using Statistics\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated, partition\n",
    "using Printf, BSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification using a multi-layer-perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the MLP to go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "imgs = Flux.Data.MNIST.images()\n",
    "\n",
    "# Stack into one batch\n",
    "X = hcat(float.(reshape.(imgs, :))...);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels\n",
    "labels = Flux.Data.MNIST.labels()\n",
    "\n",
    "# One-hot-encode the labels\n",
    "Y = onehotbatch(labels, 0:9);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the MLP\n",
    "m = Chain(\n",
    "    Dense(28^2, 32, relu),\n",
    "    Dense(32, 10),\n",
    "    softmax\n",
    ")\n",
    "\n",
    "loss(x, y) = crossentropy(m(x), y)\n",
    "accuracy(x, y) = mean(onecold(m(x)) .== onecold(y));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(X, Y) = 2.3216996f0\n",
      "loss(X, Y) = 2.0873454f0\n",
      "loss(X, Y) = 1.8983456f0\n",
      "loss(X, Y) = 1.7171309f0\n",
      "loss(X, Y) = 1.5390797f0\n",
      "loss(X, Y) = 1.3663688f0\n",
      "loss(X, Y) = 1.2474085f0\n",
      "loss(X, Y) = 1.1391566f0\n",
      "loss(X, Y) = 1.0431044f0\n",
      "loss(X, Y) = 0.9589184f0\n",
      "loss(X, Y) = 0.88494235f0\n",
      "loss(X, Y) = 0.80148685f0\n",
      "loss(X, Y) = 0.73233825f0\n",
      "loss(X, Y) = 0.6742944f0\n",
      "loss(X, Y) = 0.6369574f0\n",
      "loss(X, Y) = 0.60460365f0\n",
      "loss(X, Y) = 0.57656044f0\n",
      "loss(X, Y) = 0.55203193f0\n",
      "loss(X, Y) = 0.5237859f0\n",
      "loss(X, Y) = 0.4997492f0\n",
      "loss(X, Y) = 0.47909763f0\n",
      "loss(X, Y) = 0.46123615f0\n",
      "loss(X, Y) = 0.44564414f0\n",
      "loss(X, Y) = 0.4318972f0\n",
      "loss(X, Y) = 0.41966504f0\n",
      "loss(X, Y) = 0.40868494f0\n",
      "loss(X, Y) = 0.39876556f0\n",
      "loss(X, Y) = 0.38974342f0\n",
      "loss(X, Y) = 0.38147405f0\n",
      "loss(X, Y) = 0.37383783f0\n",
      "loss(X, Y) = 0.366751f0\n",
      "loss(X, Y) = 0.3601332f0\n",
      "loss(X, Y) = 0.35392383f0\n",
      "loss(X, Y) = 0.34807175f0\n",
      "loss(X, Y) = 0.34254754f0\n",
      "loss(X, Y) = 0.33732703f0\n",
      "loss(X, Y) = 0.3323816f0\n",
      "loss(X, Y) = 0.3276865f0\n",
      "loss(X, Y) = 0.32321966f0\n",
      "loss(X, Y) = 0.3189578f0\n",
      "loss(X, Y) = 0.31489488f0\n",
      "loss(X, Y) = 0.31101373f0\n",
      "loss(X, Y) = 0.3072886f0\n",
      "loss(X, Y) = 0.30369672f0\n",
      "loss(X, Y) = 0.30023333f0\n",
      "loss(X, Y) = 0.29690763f0\n",
      "loss(X, Y) = 0.2936811f0\n",
      "loss(X, Y) = 0.29056197f0\n",
      "loss(X, Y) = 0.28754073f0\n",
      "loss(X, Y) = 0.28461036f0\n",
      "loss(X, Y) = 0.28177762f0\n",
      "loss(X, Y) = 0.2790343f0\n",
      "loss(X, Y) = 0.2763793f0\n"
     ]
    }
   ],
   "source": [
    "# Set up the training\n",
    "dataset = repeated((X, Y), 200)\n",
    "evalcb = () -> @show(loss(X, Y))\n",
    "opt = ADAM()\n",
    "\n",
    "Flux.train!(loss, params(m), dataset, opt, cb = throttle(evalcb, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9237166666666666"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assess the accuracy\n",
    "accuracy(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.924"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the test set accuracy\n",
    "tX = hcat(float.(reshape.(Flux.Data.MNIST.images(:test), :))...)\n",
    "tY = onehotbatch(Flux.Data.MNIST.labels(:test), 0:9)\n",
    "\n",
    "accuracy(tX, tY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification using a convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels and images\n",
    "train_labels = Flux.Data.MNIST.labels()\n",
    "train_imgs = Flux.Data.MNIST.images();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct minibatches\n",
    "function make_minibatch(X, Y, idxs)\n",
    "    X_batch = Array{Float32}(undef, size(X[1])..., 1, length(idxs))\n",
    "    for i in 1:length(idxs)\n",
    "        X_batch[:, :, :, i] = Float32.(X[idxs[i]])\n",
    "    end\n",
    "    Y_batch = onehotbatch(Y[idxs], 0:9)\n",
    "    return (X_batch, Y_batch)\n",
    "end\n",
    "\n",
    "batch_size = 128\n",
    "mb_idxs = partition(1:length(train_imgs), batch_size)\n",
    "train_set = [make_minibatch(train_imgs, train_labels, i) for i in mb_idxs]\n",
    "\n",
    "# Test set as one minibatch\n",
    "test_imgs = Flux.Data.MNIST.images(:test)\n",
    "test_labels = Flux.Data.MNIST.labels(:test)\n",
    "test_set = make_minibatch(test_imgs, test_labels, 1:length(test_imgs));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional architecture with three iterations of Conv -> ReLU -> MaxPool followed by\n",
    "# a final dense layer fed into a softmax probability output\n",
    "model = Chain(\n",
    "    # 1st convolutional layer, taking a 28x28 image\n",
    "    Conv((3, 3), 1=>16, pad=(1, 1), relu),\n",
    "    MaxPool((2, 2)),\n",
    "    \n",
    "    # 2nd convolutional layer, taking a 14x14 image\n",
    "    Conv((3, 3), 16=>32, pad=(1, 1), relu),\n",
    "    MaxPool((2, 2)),\n",
    "    \n",
    "    # 3rd convolutional layer, taking a 7x7 image\n",
    "    Conv((3, 3), 32=>32, pad=(1, 1), relu),\n",
    "    MaxPool((2, 2)),\n",
    "    \n",
    "    # Reshape 3d tensor into a 2d tensor of shape (3, 3, 32, N)\n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    Dense(288, 10),\n",
    "    \n",
    "    # Softmax output layer\n",
    "    softmax,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is enabled uncomment the lines below to load the model onto a GPU\n",
    "#train_set = gpu.(train_set)\n",
    "#test_set = gpu.(test_set)\n",
    "#model = gpu(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×128 Array{Float32,2}:\n",
       " 0.0856447  0.0855172  0.0793483  …  0.080293   0.0805311  0.0820767\n",
       " 0.0863398  0.088711   0.0882837     0.0896656  0.0868811  0.0903626\n",
       " 0.112502   0.108703   0.108787      0.114588   0.108995   0.109684 \n",
       " 0.102752   0.107586   0.102949      0.110352   0.106419   0.108801 \n",
       " 0.109906   0.111776   0.107399      0.104055   0.108576   0.103853 \n",
       " 0.0880292  0.0881556  0.101727   …  0.0896815  0.0892337  0.0925875\n",
       " 0.122918   0.121647   0.106211      0.124256   0.12633    0.115889 \n",
       " 0.100094   0.0967535  0.10436       0.0969488  0.0951824  0.099685 \n",
       " 0.0926575  0.0917759  0.101075      0.0935281  0.098061   0.100009 \n",
       " 0.0991572  0.0993751  0.09986       0.0966319  0.0997908  0.0970526"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precompile the model\n",
    "model(train_set[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crossentropy loss between prediction and ground truth, add Gaussian noise to make model more robust\n",
    "function loss(x, y)\n",
    "    # Add random noise to x\n",
    "    x_aug = x .+ 0.1f0 * randn(eltype(x), size(x))\n",
    "    \n",
    "    y_hat = model(x_aug)\n",
    "    return crossentropy(y_hat, y)\n",
    "end\n",
    "\n",
    "accuracy(x, y) = mean(onecold(model(x)) .== onecold(y));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ADAM as the optimizer\n",
    "opt = ADAM(0.001)\n",
    "\n",
    "best_acc = 0.0\n",
    "last_improvement = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: [1]: Test accuracy: 0.9731\n",
      "└ @ Main In[45]:10\n"
     ]
    },
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] macro expansion at ./threadingconstructs.jl:75 [inlined]",
      " [2] #conv_im2col!#159(::Array{Float32,3}, ::Float32, ::Float32, ::typeof(NNlib.conv_im2col!), ::Array{Float32,5}, ::Array{Float32,5}, ::Array{Float32,5}, ::DenseConvDims{3,(3, 3, 1),32,32,(1, 1, 1),(1, 1, 1, 1, 0, 0),(1, 1, 1),false}) at /home/lpaehler/.julia/packages/NNlib/3krvM/src/impl/conv_im2col.jl:49",
      " [3] conv_im2col! at /home/lpaehler/.julia/packages/NNlib/3krvM/src/impl/conv_im2col.jl:30 [inlined]",
      " [4] #conv!#41 at /home/lpaehler/.julia/packages/NNlib/3krvM/src/conv.jl:53 [inlined]",
      " [5] conv!(::Array{Float32,5}, ::Array{Float32,5}, ::Array{Float32,5}, ::DenseConvDims{3,(3, 3, 1),32,32,(1, 1, 1),(1, 1, 1, 1, 0, 0),(1, 1, 1),false}) at /home/lpaehler/.julia/packages/NNlib/3krvM/src/conv.jl:53",
      " [6] #conv!#48(::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::typeof(conv!), ::Array{Float32,4}, ::Array{Float32,4}, ::Array{Float32,4}, ::DenseConvDims{2,(3, 3),32,32,(1, 1),(1, 1, 1, 1),(1, 1),false}) at /home/lpaehler/.julia/packages/NNlib/3krvM/src/conv.jl:70",
      " [7] conv! at /home/lpaehler/.julia/packages/NNlib/3krvM/src/conv.jl:70 [inlined]",
      " [8] #conv#89(::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::typeof(conv), ::Array{Float32,4}, ::Array{Float32,4}, ::DenseConvDims{2,(3, 3),32,32,(1, 1),(1, 1, 1, 1),(1, 1),false}) at /home/lpaehler/.julia/packages/NNlib/3krvM/src/conv.jl:116",
      " [9] conv(::Array{Float32,4}, ::Array{Float32,4}, ::DenseConvDims{2,(3, 3),32,32,(1, 1),(1, 1, 1, 1),(1, 1),false}) at /home/lpaehler/.julia/packages/NNlib/3krvM/src/conv.jl:114",
      " [10] #adjoint#1653 at /home/lpaehler/.julia/packages/Zygote/oMScO/src/lib/nnlib.jl:21 [inlined]",
      " [11] adjoint at ./none:0 [inlined]",
      " [12] _pullback at /home/lpaehler/.julia/packages/ZygoteRules/6nssF/src/adjoint.jl:47 [inlined]",
      " [13] Conv at /home/lpaehler/.julia/packages/Flux/2i5P1/src/layers/conv.jl:55 [inlined]",
      " [14] _pullback(::Zygote.Context, ::Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}}, ::Array{Float32,4}) at /home/lpaehler/.julia/packages/Zygote/oMScO/src/compiler/interface2.jl:0",
      " [15] applychain at /home/lpaehler/.julia/packages/Flux/2i5P1/src/layers/basic.jl:30 [inlined]",
      " [16] _pullback(::Zygote.Context, ::typeof(Flux.applychain), ::Tuple{Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},MaxPool{2,4},getfield(Main, Symbol(\"##21#22\")),Dense{typeof(identity),Array{Float32,2},Array{Float32,1}},typeof(softmax)}, ::Array{Float32,4}) at /home/lpaehler/.julia/packages/Zygote/oMScO/src/compiler/interface2.jl:0",
      " [17] applychain at /home/lpaehler/.julia/packages/Flux/2i5P1/src/layers/basic.jl:30 [inlined]",
      " [18] _pullback(::Zygote.Context, ::typeof(Flux.applychain), ::Tuple{MaxPool{2,4},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},MaxPool{2,4},getfield(Main, Symbol(\"##21#22\")),Dense{typeof(identity),Array{Float32,2},Array{Float32,1}},typeof(softmax)}, ::Array{Float32,4}) at /home/lpaehler/.julia/packages/Zygote/oMScO/src/compiler/interface2.jl:0",
      " [19] applychain at /home/lpaehler/.julia/packages/Flux/2i5P1/src/layers/basic.jl:30 [inlined]",
      " [20] _pullback(::Zygote.Context, ::typeof(Flux.applychain), ::Tuple{Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},MaxPool{2,4},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},MaxPool{2,4},getfield(Main, Symbol(\"##21#22\")),Dense{typeof(identity),Array{Float32,2},Array{Float32,1}},typeof(softmax)}, ::Array{Float32,4}) at /home/lpaehler/.julia/packages/Zygote/oMScO/src/compiler/interface2.jl:0",
      " [21] applychain at /home/lpaehler/.julia/packages/Flux/2i5P1/src/layers/basic.jl:30 [inlined]",
      " [22] _pullback(::Zygote.Context, ::typeof(Flux.applychain), ::Tuple{MaxPool{2,4},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},MaxPool{2,4},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},MaxPool{2,4},getfield(Main, Symbol(\"##21#22\")),Dense{typeof(identity),Array{Float32,2},Array{Float32,1}},typeof(softmax)}, ::Array{Float32,4}) at /home/lpaehler/.julia/packages/Zygote/oMScO/src/compiler/interface2.jl:0",
      " [23] applychain at /home/lpaehler/.julia/packages/Flux/2i5P1/src/layers/basic.jl:30 [inlined]",
      " [24] _pullback(::Zygote.Context, ::typeof(Flux.applychain), ::Tuple{Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},MaxPool{2,4},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},MaxPool{2,4},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},MaxPool{2,4},getfield(Main, Symbol(\"##21#22\")),Dense{typeof(identity),Array{Float32,2},Array{Float32,1}},typeof(softmax)}, ::Array{Float32,4}) at /home/lpaehler/.julia/packages/Zygote/oMScO/src/compiler/interface2.jl:0",
      " [25] Chain at /home/lpaehler/.julia/packages/Flux/2i5P1/src/layers/basic.jl:32 [inlined]",
      " [26] _pullback(::Zygote.Context, ::Chain{Tuple{Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},MaxPool{2,4},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},MaxPool{2,4},Conv{2,2,typeof(relu),Array{Float32,4},Array{Float32,1}},MaxPool{2,4},getfield(Main, Symbol(\"##21#22\")),Dense{typeof(identity),Array{Float32,2},Array{Float32,1}},typeof(softmax)}}, ::Array{Float32,4}) at /home/lpaehler/.julia/packages/Zygote/oMScO/src/compiler/interface2.jl:0",
      " [27] loss at ./In[31]:6 [inlined]",
      " [28] _pullback(::Zygote.Context, ::typeof(loss), ::Array{Float32,4}, ::Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}) at /home/lpaehler/.julia/packages/Zygote/oMScO/src/compiler/interface2.jl:0",
      " [29] adjoint at /home/lpaehler/.julia/packages/Zygote/oMScO/src/lib/lib.jl:153 [inlined]",
      " [30] _pullback at /home/lpaehler/.julia/packages/ZygoteRules/6nssF/src/adjoint.jl:47 [inlined]",
      " [31] #15 at /home/lpaehler/.julia/packages/Flux/2i5P1/src/optimise/train.jl:69 [inlined]",
      " [32] _pullback(::Zygote.Context, ::getfield(Flux.Optimise, Symbol(\"##15#21\")){typeof(loss),Tuple{Array{Float32,4},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}}}) at /home/lpaehler/.julia/packages/Zygote/oMScO/src/compiler/interface2.jl:0",
      " [33] pullback(::Function, ::Zygote.Params) at /home/lpaehler/.julia/packages/Zygote/oMScO/src/compiler/interface.jl:96",
      " [34] gradient(::Function, ::Zygote.Params) at /home/lpaehler/.julia/packages/Zygote/oMScO/src/compiler/interface.jl:46",
      " [35] macro expansion at /home/lpaehler/.julia/packages/Flux/2i5P1/src/optimise/train.jl:68 [inlined]",
      " [36] macro expansion at /home/lpaehler/.julia/packages/Juno/oLB1d/src/progress.jl:134 [inlined]",
      " [37] #train!#12(::getfield(Flux.Optimise, Symbol(\"##16#22\")), ::typeof(Flux.Optimise.train!), ::Function, ::Zygote.Params, ::Array{Tuple{Array{Float32,4},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}},1}, ::ADAM) at /home/lpaehler/.julia/packages/Flux/2i5P1/src/optimise/train.jl:66",
      " [38] train!(::Function, ::Zygote.Params, ::Array{Tuple{Array{Float32,4},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}},1}, ::ADAM) at /home/lpaehler/.julia/packages/Flux/2i5P1/src/optimise/train.jl:64",
      " [39] top-level scope at ./In[45]:6"
     ]
    }
   ],
   "source": [
    "# Define the training loop and train for 100 epochs\n",
    "for epoch_idx in 1:100\n",
    "    global best_acc, last_improvement\n",
    "    \n",
    "    # Train for one epoch\n",
    "    Flux.train!(loss, params(model), train_set, opt)\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    acc = accuracy(test_set...)\n",
    "    @info(@sprintf(\"[%d]: Test accuracy: %.4f\", epoch_idx, acc))\n",
    "    \n",
    "    # Stop if accuracy is good enough\n",
    "    if acc >= 0.999\n",
    "        @info(\" -> Early-exiting: We reached our target accuracy of 99.9%\")\n",
    "        break\n",
    "    end\n",
    "    \n",
    "    # Reduce learning rate if there has been no improvement for 5 epochs\n",
    "    if epoch_idx - last_improvement >= 5 && opt.eta > 1e-6\n",
    "        opt.eta /= 10.0\n",
    "        @warn(\" -> Haven't improved in a while, dropping learning rate to $(opt.eta)!\")\n",
    "        \n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "    \n",
    "    if epoch_idx - last_improvement >= 10\n",
    "        @warn(\" -> The model has converged.\")\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exercise: Construct a different neural network for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look up two papers, which are more state-of-the-art and urge people to have a go at creating these models\n",
    "# Paper 1\n",
    "# Paper 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
